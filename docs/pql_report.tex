\documentclass{sig-alternate-05-2015}


\begin{document}

% Copyright
% \setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
% \doi{10.475/123_4}
% ISBN
% \isbn{123-4567-24-567/08/06}
%Conference
% \conferenceinfo{PLDI '13}{June 16--19, 2013, Seattle, WA, USA}
% \acmPrice{\$15.00}

%
% --- Author Metadata here ---
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Learning through play: Iterative query-seeking through partial query specification}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

% \numberofauthors{8} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
% \author{ }
\maketitle
\begin{abstract}
Abstract
\end{abstract}


% \keywords{ACM proceedings; \LaTeX; text tagging}
\section{Introduction}
Formulating ad-hoc database queries for exploratory data analysis is a challenging problem for analysts. Prior work in query by example and query synthesis address this by inferring candidate queries based on input and output data examples and visual query construction through a specification interface.  However, the more pressing challenge for both novice and expert analysts is often coming up with the right question to ask. Most of these prior work have focussed on intent-to-query mapping mechanisms that assume users have a question in mind to begin with. Therefore, these work focuses on resolving the “language barrier” to help novices unfamiliar with SQL issue queries to the database. Users often only have minimal or partial ideas on what types of data operations they would like to perform or the types of query they are interested in.  Moreover, while existing database query interface are capable of synthesizing SQL queries based on high-level specifications, the space of queries that could be issued with these interface are often limited by the set of form fields and interactions envisioned by tool-designers. A more natural mode of interaction is perhaps to specify the units of interest, albeit partial, to the system, and let the system infer what is best to show the user.
To this end, we proposed a unifying querying language that captures a wide spectrum of input query specificity (from no user input to complete query specification), called partial query language (PQL). Unlike structured querying language, such as SQL and XQuery, which monolithic and evaluates only upon exact specification, PQL is tolerant to the inherent ambiguity of user specification. PQL takes in an underspecified query during exploratory data analysis, the system uses a rule-based template to execute suggested actions, and updates the next set of recommendations based on users feedback on the seen output. The goal of PQL is to simultaneously enable flexible querying as well as gain better understanding of the dataset to facilitate users to discover the interesting questions to ask.
% These underspecified query can include requests for overviews, uncertain attributes selections, or view suggestions within a range query. 

%\begin{figure}
%\centering
%\includegraphics[height=1in, width=1in]{fly}
%\caption{A sample black and white graphic
%that has been resized with the \texttt{includegraphics} command.}
%\end{figure}

Contribution: 
\begin{itemize}
\item unifying model for inference
\item vizRec that account for feedback (not based on logs)
\end{itemize}
% The first two are language features of PQL and the latter two requirements are related to the PQL engine. 

Our key idea is to make use of feedback to support partial queries. 
IR relevance feedback
idea that queries are hard to come up with, but it should be easy to rate something or say if it is relevant or not. 
Dataplay has this with "want-in", "want-out example"
\section{Motivation \& Related Works}
\par Depsite extensive work on making database usable, there is an inevitable design tradeoff between the query expressivity and interface usability that depends on user's expertise and workload\cite{Jagadish2007,Morton2014}. Given that there is no one size fit all interface for query specification, PQL is designed as a middlelayer between the interface and querying engine that can take in a wide spectrum of queries of different input types and degrees of specificity that could be potentially generated from these interfaces. Here we list the potential query inputs in order of increasing specificity: 
\begin{itemize}
\item Cold-start: no supervision, only given the dataset as input (viz-summarization).
\item \textbf{Example-based partial queries (EPQ):} EPQs takes in data examples based on what they have already seen and use this to jumpstart their query. 
%\par Given an EPQ, PQL infers and suggest potential explanations or queries based on the data the user provides as a query. 
%A crucial difference that separates our work and QBE is that the goal of EDPQ is to generate potential explanations or query recommendations rather than generating a query that will address a predefined question. As a result, EDPQ has a more relaxed set of constraints compared to typical scenario in the query synthesis problem, which leads to a larger search space potential queries that offer further opportunities for optimization.
\par Existing work in the area of Query-by-Examples (QBE) asks users to provide I/O examples of the query to be synthesized. However, if the user does not know what they are querying for, then they would not be able to come up with such an example. In addition, EPQ accepts a more easy-to-come-up-with input modalities such as visualization distributions or an existing singleton record as examples to query. The types of inputs could be largely classified in two categories: 1) Record querying: querying via non-aggregated set of tuples or visualizations as input (e.g. drag-and-drop in Zenvisage, smart drill down) or 2) Result querying: querying via transformed tuples (aggregation, top-k), often for offerring explainations\cite{Chapman2009,Wu2013,Roy2015}.
%These example inputs to queries comes from the results of support queries. Support queries are queries that are non-essential in answering the queries, but provide auxcillary information that could help users jumpstart in their hypothesis generation. Examples of support queries includes requests to overview representatives, outliers, and other statistics, or generate different types of visualizations. These support queries can be either system generated (as part of suggestions and explainations) or defined by the user. 
\item \textbf{Relational partial queries (RPQ):} RPQs follow the conventional approach to querying a database where a user starts with a pre-existing idea of what he is looking for based on what he has already seen or know. However, formulating SQL queries that maps user's high-level intentions to specific query statements is challenging. 
 %The way that analyst B approached the problem is an example of this. %For example, he may be trying to explore an attribute in more detail to test a hypothesis or he may be looking for examples of highly-performing young innovators. 
\par Recent work in natural language querying have tried to address this by parsing adjectives and quantifiers and asking the users for additional information to resolve the ambiguity through form-based interface if needed. Simmilar to form-based or visual query builders\cite{Abouzied2012}, these systems are often based on templated queries with limited expressiveness in their linguistic and conceptual coverage, which makes it difficult for expert users to express complex queries. SnipSuggest addresses this problem by recommending relevant snippets of SQL queries based on partial queries (user’s partially typed input) via autocomplete\cite{Khoussainova2010}. However, their context-aware algorithm crucially depends on the existence of a query workload. 
%\par Instead of approaching this problem from the perspective of ambiguity resolution, we recognize that sometimes users themselves may not have a clear cut specification of what they are asking for. As a result, we introduce the EXPLORE operator and the special value ? to increase the tolerance of ambiguity inherently in the PQL language design, then the engine takes this partial specification decide what would be the best answers or suggestions to return as an output.
%\item relational querying: SnipSuggest, DataPlay, form-based or visual query builders (ZQL)
\item Complete specification : At the highest level of specification there is SQL and direct manipulation interfaces that performs database operations based on complete specification.
\end{itemize}
these two inter-related modes of data exploration, where data or bottom up approaches are initiated through data examples and framing comes from specifying distribution or relationships in a top-down manner.
\section{Usage Scenario}
\par A team of analyst is a given a dataset that consist of the reported income of all the villager living in their county. They wanted to study whether there is any evidence of institutional bias worker salaries. Given this large dataset with hundreds of attributes about each individual, they are not sure where to start. The only thing they know is that their measure attribute of interest the Income column, so they specify this in PQL. In this inital step, PQL tries to provide as much support information as it can by displaying a sample table of data records arranged in the order of increasing income, the attributes are displayed in the order of most to least importance, where importance is defined by how much the feature have an impact on the measure variable of interest. By convention, the primary key is always in the first column. 
\par Given this information, analyst A was still not able to infer anything about any particular column to ask a new question, but he notice that Charlie has an incredibly low income compared to the average income. Using PQL, he can searches for other records simmilar to Charlie. He notices that all of the returned records are all young children who work part-time jobs.
\par Analyst B skims through the records  and notices that despite Mary having more years of working experience than Fred, she is getting paid \$5000 less than him. He wants to find out whether employers are marginalizing the pay of certain individuals based on gender for the same job done. Given this hypothesis, he specifies a PQL query to find women who are in Sales and have simmilar years of experience as Mary and Fred. The PQL engine generates two support queries on this selected population to display the overview statistics and histograms of the selected subpopulation and its counterpart (i.e. men who are in Sales with simmilar years of experience).
\section{PQL Design}
%Reflecting the two ---, PQL supports these two corresponding types of queries:  
The language design of PQL is motivated by several desiderata, based on the analyst's needs and limitations of existing systems:
\begin{enumerate}
	\item Tolerant to ambiguity : PQL must have a model of inference that can make inference with incomplete specification, since 1) partial queries can be used for jumpstarting the exploration of under-developed hypothesis and 2) queries can be iteratively refined by the user as user gain more information about the data to update the model. 
	\item Composability: PQL operators must be composable to increase the expressiveness of PQL in supporting a large class of ad-hoc queries, so that analysts are not constrained when exploring the types of questions they might want to ask.
	\item Supporting both records and relations as inputs : Given the prior work of how analyst make sense of their data\cite{Pirolli2005,Klein2006}, PQL must support both bottom-up example records and top-down relational specification of queries. As shown in the usage scenario, given the same data output, different analysts may have different interpretation and approach the same dataset and problem. %PQL enables analysts to seamlessly switch between the two modes of inquiry as shown in Figure \ref{architecture}.  %Popular theories in data sensemaking have suggested two different symbiotic modes of operations for understanding data. Pirolli and Card’s notional model describes information processing as an ``opportunistic mix'' between top-down (from theory to data) and bottom-up (from data to theory) tasks\cite{Pirolli2005}. Similarly, the Data/Frame theory suggests that the data analysis process is a closed-loop transition between an effort to recognize or construct a frame through data or defining connections amongst the seen data\cite{Klein2006}. 
	%\item Ability to suggest possible actions: The suggestion can come in two forms: 1) Given a partial query, suggest the possible queries that are \textit{simmilar in functionality} or 2) Given a data example or resultset, suggest possible next steps or actions that reflect \textit{simmilar data relationships}.
	%\item Model takes in feedback
	% \item Ability to generate explainations: Simmilarly explaination could be 1) by-example: data/record-level locality, or 2) by theory: membership or behaviour locality.
\end{enumerate}

PQL can be written in terms of action-operators and goal definitions. Goal definitions specifies the attributes and records that users are interested in. There are three types of goal definitions supported by PQL: 
\begin{itemize}
	\item Attribute-value of interest (e.g. GENDER= 'Female')
	\item Attribute of interest (e.g. GENDER): can either be a measure or dimension. Measure of interest have a special significance in the algorithm.
	%OBJECTIVE $M$ : Defining the measure value of interest during the analysis as M.
	\item Examples $\{r_1 ...r_n\}$
\end{itemize}
 All action-operators can be decomposed as a set of goal definitions. 



Action-operators takes a record ($r_i$) or relation ($A_i$) as inputs and outputs and performs some action. 
\begin{itemize}
	\item EXPLORE $r_i$: Given a data record, explore  
	\item EXPLORE $\{A_1 ...A_n\}$: 
	\item EXPLAIN $r_i$: 
	\item EXPLAIN $\{A_1 ...A_n\}$:
	\item LIKE $r_i$: Find records that are simmilar to $r_i$.
	\item COMPARE $\{r_1 ...r_n\}$: Compare between records that are different 
	\item DISTINGUISH $r_i$: Find what is the distinguishing feature of $r_i$ 
\end{itemize}

% \par Using the example table shown in Figure.\ref{edpq_example}, examples of EDPQ includes: 
% Given a queried record, 
% PQL engine generates \textit{support queries}.
%the ability to work with individual record-level examples and compare  

\section{Problem Formulation}
Since the space of operators for a given input is limited, finding the best action to perform is not hard. 
 involves finding the most suitable attribute or relations to perform the action on.
\section{System architecture}

\section{Project Scope}

\bibliographystyle{abbrv}
\bibliography{reference}  
\end{document}
